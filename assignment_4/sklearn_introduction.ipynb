{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img src=\"images/meme.png\">\n",
    "</center>\n",
    "\n",
    "# Машинное обучение  \n",
    "> Компьютерная программа обучается на основе опыта $E$ по отношению к некоторому классу задач $T$ и меры качества $P$, если качество решения задач из $T$, измеренное на основе $P$, улучшается с приобретением опыта $E$. (Т. М. Митчелл)\n",
    "\n",
    "### Формулировка задачи:  \n",
    "$X$ $-$ множество объектов  \n",
    "$Y$ $-$ множество меток классов  \n",
    "$f: X \\rightarrow Y$ $-$ неизвестная зависимость  \n",
    "**Дано**:  \n",
    "$x_1, \\dots, x_n \\subset X$ $-$ обучающая выборка  \n",
    "$y_i = f(x_i), i=1, \\dots n$ $-$ известные метки классов  \n",
    "**Найти**:  \n",
    "$a∶ X \\rightarrow Y$ $-$ алгоритм, решающую функцию, приближающую $f$ на всём множестве $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c intel scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "numpy.random.seed(7)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "print(X.shape)\n",
    "\n",
    "random_sample = numpy.random.choice(X.shape[0], 10)\n",
    "for i in random_sample:\n",
    "    print(f\"{X[i]}: {iris.target_names[Y[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы задач\n",
    "\n",
    "### Задача классификации\n",
    "\n",
    "$Y = \\{ -1, +1 \\}$ $-$ классификация на 2 класса;  \n",
    "$Y = \\{1, \\dots , K \\}$ $-$ на $K$ непересекающихся классов;  \n",
    "$Y = \\{0, 1 \\}^K$ $-$ на $K$ классов, которые могут пересекаться.\n",
    "\n",
    "Примеры: распознавание текста по рукописному вводу, определение предмета на фотографии.\n",
    "\n",
    "### Задача регрессии\n",
    "\n",
    "$Y = \\mathbb{R}$ или $Y = \\mathbb{R}^k$.\n",
    "\n",
    "Примеры: предсказание стоимости акции через полгода, предсказание прибыли магазина в следующем месяце.\n",
    "\n",
    "### Задача ранжирования\n",
    "\n",
    "$Y$ $-$ конечное упорядоченное множество.\n",
    "\n",
    "Пример: выдача поискового запроса.\n",
    "\n",
    "### Задачи уменьшения размерности\n",
    "\n",
    "Научиться описывать данные не $M$ признаками, а меньшим числом для повышения точности модели или последующей визуализации. В качестве примера помимо необходимости для визуализации можно привести сжатие данных.\n",
    "\n",
    "### Задачи кластеризации\n",
    "\n",
    "Разбиение данных множества объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию. \n",
    "\n",
    "<center>\n",
    "    <img src=\"images/ml_map.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(random_state=7)\n",
    "model.fit(X, Y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "for i in random_sample:\n",
    "    print(f\"predicted: {iris.target_names[y_pred[i]]}, actual: {iris.target_names[Y[i]]}\")\n",
    "    \n",
    "f\"differences in {(Y != y_pred).sum()} samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества\n",
    "\n",
    "## Метрика\n",
    "\n",
    "### Задача классификации\n",
    "\n",
    "Определим матрицу ошибок. Допустим, что у нас есть два класса и алгоритм, предсказывающий принадлежность каждого объекта одному из классов, тогда матрица ошибок классификации будет выглядеть следующим образом:\n",
    "\n",
    "| $ $         | $y=1$               | $y=0$               |  \n",
    "|-------------|---------------------|---------------------|  \n",
    "| $\\hat{y}=1$ | True Positive (TP)  | False Positive (FP) |  \n",
    "| $\\hat{y}=0$ | False Negative (FN) | True Negative (TN)  |  \n",
    "\n",
    "Здесь $\\hat{y}$ $-$ это ответ алгоритма на объекте, а $y$ $-$ истинная метка класса на этом объекте.  \n",
    "Таким образом, ошибки классификации бывают двух видов: *False Negative (FN)* и *False Positive (FP)*.\n",
    "\n",
    "- $\\textit{accuracy} = \\frac{TP + TN}{TP + FP + FN + TN}$\n",
    "- $\\textit{recall} = \\frac{TP}{TP + FN}$\n",
    "- $\\textit{precision} = \\frac{TP}{TP + FP}$\n",
    "- $\\textit{f1-score} = \\frac{2 \\cdot \\textit{recall} \\cdot \\textit{precision}}{\\textit{precision} + \\textit{recall}}$\n",
    "\n",
    "### Задача регрессии\n",
    "\n",
    "- $MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$\n",
    "- $RMSE = \\sqrt{MSE}$\n",
    "- $MAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|$\n",
    "\n",
    "## Отложенная выборка\n",
    "\n",
    "$X \\rightarrow X_{train}, X_{val}, X_{test}$\n",
    "\n",
    "- $X_{train}$ $-$ используется для обучения модели\n",
    "- $X_{val}$ $-$ подбор гиперпараметров ($ \\approx{30\\%}$ от тренировочной части)\n",
    "- $X_{test}$ $-$ оценка качества конечной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# 1/3 всего датасета возьмём для тестовой выборки\n",
    "# затем 30% от тренировочной будет валидационной\n",
    "test_index = numpy.random.choice(X.shape[0], X.shape[0] // 3)\n",
    "train_index = [i for i in range(X.shape[0]) if i not in test_index]\n",
    "\n",
    "X_test = X[test_index]\n",
    "Y_test = Y[test_index]\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X[train_index], Y[train_index], test_size=0.3, shuffle=True, random_state=7)\n",
    "\n",
    "print(f\"train size: {X_train.shape[0]}\")\n",
    "print(f\"val size: {X_val.shape[0]}\")\n",
    "print(f\"test size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -1\n",
    "best_c = None\n",
    "\n",
    "for c in [0.01, 0.1, 1, 10]:\n",
    "    model = SVC(C=c, random_state=7)\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    cur_score = f1_score(Y_val, y_pred, average='micro')\n",
    "    if cur_score > best_score:\n",
    "        best_score = cur_score\n",
    "        best_c = c\n",
    "\n",
    "f\"best score is {best_score} for C {best_c}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = SVC(C=1.0, random_state=7)\n",
    "full_model.fit(X[train_index], Y[train_index])\n",
    "y_pred = full_model.predict(X_test)\n",
    "f\"test score is {f1_score(Y_test, y_pred, average='micro')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы классификации\n",
    "\n",
    "## Линейный классификатор\n",
    "\n",
    "Построение разделяющей гиперплоскости\n",
    "\n",
    "$$\n",
    "y = \\textit{sign}(Wx + b)\n",
    "$$\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/linear_classifier.png\">\n",
    "</center>\n",
    "\n",
    "### Стандартизация величин\n",
    "\n",
    "При использование линейных моделей, иногда полезно стандартизировать их значения, например, оценки пользователей.\n",
    "\n",
    "$$\n",
    "X_{stand} = \\frac{X - X_{mean}}{X_{std}}\n",
    "$$\n",
    "\n",
    "Для этого в `sklearn` есть класс $-$ `StandartScaler`\n",
    "\n",
    "\n",
    "### Логистическая регрессия\n",
    "\n",
    "Использование функции логита для получения вероятности\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/logit.png\">\n",
    "</center>\n",
    "\n",
    "## Метод опорных векторов (Support vector machine)\n",
    "\n",
    "Построение \"полоски\" максимальной ширины, которая разделяет выборку\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/svm.png\">\n",
    "</center>\n",
    "\n",
    "\n",
    "## Дерево решений (Decision tree)\n",
    "\n",
    "В каждой вершине определяется критерий, по которому разбивается подвыборка.\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/decision_tree.png\">\n",
    "</center>\n",
    "\n",
    "## Случайный лес (Random forest)\n",
    "\n",
    "Множество деревьев решений, каждое из которых обучается на случайной подвыборке.\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/random_forest.png\">\n",
    "</center>\n",
    "\n",
    "## Метод ближайших соседей (K-neighbors)\n",
    "\n",
    "Решение базируется на основе $k$ ближайших известных примеров.\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/knn.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=50, n_informative=20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(random_state=7, n_jobs=6),\n",
    "    SVC(random_state=7),\n",
    "    DecisionTreeClassifier(random_state=7),\n",
    "    RandomForestClassifier(random_state=7),\n",
    "    KNeighborsClassifier(n_jobs=6)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"model {model.__class__.__name__} scores {round(f1_score(y_test, y_pred, average='micro'), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standart_scaler = StandardScaler()\n",
    "standart_scaler.fit(X_train)\n",
    "X_train_scaled = standart_scaler.transform(X_train)\n",
    "X_test_scaled = standart_scaler.transform(X_test)\n",
    "\n",
    "model = SVC(random_state=7)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "f\"test score is {f1_score(y_test, y_pred, average='micro')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclass task #1\n",
    "\n",
    "Реализуйте модель, которая классифицирует цифры по рисунку.\n",
    "\n",
    "Ваша задача получить f1-score $0.98$ на тестовом датасете.\n",
    "\n",
    "Можете пользоваться как алгоритмами выше, так и любыми другими реализованными в `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, Y = fetch_openml('mnist_784', return_X_y=True)\n",
    "print(f\"shape of X is {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 5))\n",
    "\n",
    "for i, num in enumerate(numpy.random.choice(X.shape[0], 10)):\n",
    "    axes[i // 5, i % 5].matshow(X[num].reshape(28, 28))\n",
    "    axes[i // 5, i % 5].set_title(Y[num])\n",
    "    axes[i // 5, i % 5].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shuffle = numpy.random.permutation(X.shape[0])\n",
    "\n",
    "X_test, X_train = X[test_shuffle[:10000]], X[test_shuffle[10000:]]\n",
    "Y_test, Y_train = Y[test_shuffle[:10000]], Y[test_shuffle[10000:]]\n",
    "\n",
    "print(f\"train size: {X_train.shape[0]}\")\n",
    "print(f\"test size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "####### Your code here #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(f\"test score is {f1_score(Y_test, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы регрессии\n",
    "\n",
    "Деревья решений, случайный лес и метод ближайших соседей легко обобщаются на случай регрессии. Ответ, как правило, это среднее из полученных значений (например, среднее значение ближайших примеров). \n",
    "\n",
    "## Линейная регрессия\n",
    "\n",
    "$y$ линейно зависим от $x$, т.е. имеет место уравнение\n",
    "$$\n",
    "y = Wx + b = W <x; 1>\n",
    "$$\n",
    "\n",
    "Такой подход имеет аналитическое решение, однако он требует вычисление обратной матрицы $X$, что не всегда возможно.  \n",
    "Другой подход $-$ минимизация функции ошибки, например $MSE$, с помощью техники градиентного спуска.\n",
    "\n",
    "## Регуляризация\n",
    "\n",
    "Чтобы избегать переобучения (когда модель хорошо работает только на тренировочных данных) используют различные техники *регуляризации*.  \n",
    "Один из признаков переобучения $-$ модель имеет большие веса, это можно контролировать путём добавления $L1$ или $L2$ нормы весов к функции ошибки.  \n",
    "То есть, итоговая ошибка, которая будет распространятся на веса модели, считается по формуле:\n",
    "$$\n",
    "Error(W) = MSE(W, X, y) + \\lambda ||W||\n",
    "$$\n",
    "\n",
    "Такие модели, так же реализованы в `sklearn`:\n",
    "- Lasso\n",
    "- Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models = [\n",
    "    Lasso(random_state=7),\n",
    "    Ridge(random_state=7),\n",
    "    LinearRegression(n_jobs=6),\n",
    "    RandomForestRegressor(random_state=7, n_jobs=6),\n",
    "    KNeighborsRegressor(n_jobs=6),\n",
    "    SVR()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"model {model.__class__.__name__} scores {round(mean_squared_error(y_test, y_pred), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclass task #2\n",
    "\n",
    "Реализуйте модель, которая предсказывает стоимость медицинской страховки. В данных есть текстовые бинарные признаки (`sex` и `smoker`), не забудьте конвертировать их в `0` и `1`. Признак `region` имеет $4$ разных значения, вы можете конвертировать их в числа $0-4$ или создать $4$ бинарных признака. Для этого вам может помочь `sklearn.preprocessing.LabelEncoder` и `pandas.get_dummies`.\n",
    "\n",
    "Ваша задача получить RMSE-score меньше $5000$ на тестовом датасете.\n",
    "\n",
    "Можете пользоваться как алгоритмами выше, так и любыми другими реализованными в `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return numpy.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "data = pandas.read_csv('data/insurance.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['charges'], axis=1)\n",
    "y = data['charges'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=7)\n",
    "print(f\"train size: {X_train.shape[0]}\")\n",
    "print(f\"test size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "####### Your code here #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(f\"test score is {rmse(y_test, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
